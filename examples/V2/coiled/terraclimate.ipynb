{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtualizarr and Coiled - Building a Virtual Zarr store of the Terraclimate dataset\n",
    "\n",
    "\n",
    "This notebook is an example of using Virtualizarr together with the Python distributed processing framework [Coiled](https://www.coiled.io/) to generate references using [serverless functions](https://docs.coiled.io/user_guide/functions.html). \n",
    "\n",
    "**Note:** running this notebook requires a coiled account.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dataset\n",
    "For this example, we are going to create a virtual zarr store from the [Terraclimate](https://www.climatologylab.org/terraclimate.html) dataset. Terraclimate is a monthly dataset spanning 66 years and containing 14 climate and water balance variables. It is made up of 924 individual NetCDF4 files. When represented as an Xarray dataset, it is over 1TB in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelizing `Virtualizarr` reference generation with coiled serverless functions\n",
    "Coiled serverless functions allow us to easily spin up hundreds of small VMs, which are great for individual file reference generation. We were able to process 924 netCDF files a virtual xarray dataset in about 18 minutes for ~$0.43."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "```bash\n",
    "pip install 'virtualizarr[icechunk,hdf]' coiled jupyter bokeh jupyter-server-proxy obstore\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import coiled\n",
    "import icechunk\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from obstore.store import from_url\n",
    "\n",
    "from virtualizarr import open_virtual_dataset\n",
    "from virtualizarr.parsers import HDFParser\n",
    "from virtualizarr.registry import ObjectStoreRegistry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Terraclimate variable and year url combinations \n",
    "`14 variables * 66 years = 924 NetCDF files`\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = [\n",
    "    \"aet\",\n",
    "    \"def\",\n",
    "    \"pet\",\n",
    "    \"ppt\",\n",
    "    \"q\",\n",
    "    \"soil\",\n",
    "    \"srad\",\n",
    "    \"swe\",\n",
    "    \"tmax\",\n",
    "    \"tmin\",\n",
    "    \"vap\",\n",
    "    \"ws\",\n",
    "    \"vpd\",\n",
    "    \"PDSI\",\n",
    "]\n",
    "min_year = 1958\n",
    "max_year = 2023\n",
    "time_list = np.arange(min_year, max_year + 1, 1)\n",
    "\n",
    "urls = [\n",
    "    f\"https://climate.northwestknowledge.net/TERRACLIMATE-DATA/TerraClimate_{var}_{year}.nc\"\n",
    "    for year in time_list\n",
    "    for var in tvars\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define our Virtualizarr `Parser` and `ObjectStoreRegistry`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"https://climate.northwestknowledge.net\"\n",
    "store = from_url(bucket)\n",
    "registry = ObjectStoreRegistry({bucket: store})\n",
    "parser = HDFParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the coiled serverless function\n",
    "\n",
    "### Serverless function setup notes:\n",
    "- This coiled function is tailored to AWS\n",
    "- `vm_type=[\"m8g.medium\"]` - This is a small instance, you shouldn't need large machines for reference generation\n",
    "- `spot_policy=\"spot_with_fallback\"` is cheaper, but might have unintended consequences\n",
    "- `idle_timeout=\"10 minutes\"` workers will shut down after 10 minutes of inactivity \n",
    "- `n_workers=[10, 300]` adaptive scaling between 10 & 100 workers\n",
    "- `name` [optional] if you want to keep track of your cluster in the coiled dashboard\n",
    "\n",
    "More details can be found in the [serverless function API](https://docs.coiled.io/user_guide/functions.html#api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@coiled.function(\n",
    "    region=\"us-west-2\",\n",
    "    vm_type=[\"m8g.medium\"],\n",
    "    spot_policy=\"spot_with_fallback\",\n",
    "    arm=True,\n",
    "    idle_timeout=\"10 minutes\",\n",
    "    n_workers=[10, 100],\n",
    "    name=\"parallel_reference_generation\",\n",
    ")\n",
    "def process(url):\n",
    "    vds = open_virtual_dataset(\n",
    "        url=url,\n",
    "        parser=parser,\n",
    "        registry=registry,\n",
    "        loadable_variables=[\"time\", \"lat\", \"lon\", \"crs\"],\n",
    "    )\n",
    "    return vds\n",
    "\n",
    "\n",
    "# process.map distributes out the input file urls to coiled functions\n",
    "# retires=10 allows for individual task retires, which can be useful for inconsistent server behavior\n",
    "results = process.map(urls, retries=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Combine references into virtual dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract generator values into a list\n",
    "vds_list = [result for result in results]\n",
    "\n",
    "# combine individual refs into a virtual Xarray dataset\n",
    "\n",
    "mds = xr.combine_by_coords(\n",
    "    vds_list, combine_attrs=\"drop_conflicts\", coords=\"minimal\", compat=\"override\"\n",
    ")\n",
    "mds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the virtual dataset to Icechunk\n",
    "\n",
    "Now that we have this virtual dataset, we can write it to Icechunk. \n",
    "\n",
    "In this example we're creating a local icechunk store, but you could configure it for cloud storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_storage_conifg = icechunk.local_filesystem_storage(\"./terraclimate\")\n",
    "repo = icechunk.Repository.open_or_create(local_storage_conifg)\n",
    "session = repo.writable_session(\"main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = icechunk.RepositoryConfig.default()\n",
    "config.set_virtual_chunk_container(\n",
    "    icechunk.VirtualChunkContainer(\n",
    "        url_prefix=\"https://climate.northwestknowledge.net/\",\n",
    "        store=icechunk.http_store(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "storage = icechunk.in_memory_storage()\n",
    "repo = icechunk.Repository.create(storage, config)\n",
    "session = repo.writable_session(\"main\")\n",
    "\n",
    "mds.vz.to_icechunk(session.store)\n",
    "\n",
    "snapshot_id = session.commit(\"terraclimate reference\")\n",
    "print(snapshot_id)\n",
    "\n",
    "repo.save_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the Icechunk store with Xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds = xr.open_zarr(session.store, consolidated=False, zarr_format=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_ds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
